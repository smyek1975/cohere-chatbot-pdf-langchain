{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oaa3eXUIDE9N"
   },
   "source": [
    "# Lab 16. Evaluating a Custom Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koYBtMcrBu7g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "os.environ['COHERE_API_KEY'] = 'wiytrjNSrookxQDxxkpYc1wibwEczpLYIZ1K7r90'\n",
    "co = cohere.Client(api_key=os.getenv('COHERE_API_KEY'))\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLLs-PmKAPOj"
   },
   "source": [
    "## 1 - Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z8AD8Od-_Vs",
    "outputId": "9b1b144b-68c3-4b76-9cb5-94a103ea2248",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to call the endpoint\n",
    "def generate_text(prompt,temperature,num_gens):\n",
    "  response = co.generate(\n",
    "    model='command',\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    num_generations = num_gens,\n",
    "    stop_sequences=[\"\\n\\n\"])\n",
    "  return response\n",
    "\n",
    "# Define the prompt\n",
    "prompt=\"\"\"Turn the following message to a virtual assistant into the correct action:\n",
    "Send a message to Alison to ask if she can pick me up tonight to go to the concert together\"\"\"\n",
    "\n",
    "# Define the range of temperature values and num_generations\n",
    "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
    "num_gens = 3\n",
    "\n",
    "# Iterate generation over the range of temperature values\n",
    "print(f\"Temperature range: {temperatures}\")\n",
    "for temperature in temperatures:\n",
    "  response = generate_text(prompt,temperature,num_gens)\n",
    "  print(\"-\"*10)\n",
    "  print(f'Temperature: {temperature}')\n",
    "  print(\"-\"*10)\n",
    "  for i in range(3):\n",
    "    text = response.generations[i].text\n",
    "    likelihood = response.generations[i].likelihood\n",
    "    print(f'Generation #{i+1}')\n",
    "    print(f'Text: {text}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wOyuhhUq-Rl"
   },
   "source": [
    "# 2 - Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8Ex91fJVeth",
    "outputId": "6e501756-85ea-4531-f7b0-62e7a764fe46",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function to call the endpoint\n",
    "co = cohere.Client('JWbl7levmvVPOxPSCEM0irDDmRV1kSBJh6zJE1cT')\n",
    "def generate_text(prompt,temperature,num_gens):\n",
    "  response = co.chat(\n",
    "    model='72848e30-e7df-4481-bf3f-721ed2273609-ft', # REPLACE WITH YOUR MODEL ID\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    num_generations = num_gens,\n",
    "    stop_sequences=[\"\\n\\n\"])\n",
    "  return response\n",
    "\n",
    "# Define the prompt\n",
    "prompt=\"\"\"Turn the following message to a virtual assistant into the correct action:\n",
    "Send a message to Alison to ask if she can pick me up tonight to go to the concert together\"\"\"\n",
    "\n",
    "# Define the range of temperature values and num_generations\n",
    "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
    "num_gens = 3\n",
    "\n",
    "# Iterate generation over the range of temperature values\n",
    "print(f\"Temperature range: {temperatures}\")\n",
    "for temperature in temperatures:\n",
    "  response = generate_text(prompt,temperature,num_gens)\n",
    "  print(\"-\"*10)\n",
    "  print(f'Temperature: {temperature}')\n",
    "  print(\"-\"*10)\n",
    "  for i in range(3):\n",
    "    text = response.generations[i].text\n",
    "    likelihood = response.generations[i].likelihood\n",
    "    print(f'Generation #{i+1}')\n",
    "    print(f'Text: {text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vf-MKk4yPz8g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "58b4c372a03222d7f62c5e816fbbc1b3e33f34bb7e19673be34258cc686e1d67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
